{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Simple Linear Regression using Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing necessary libraries and datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.load_boston(return_X_y = True)\n",
    "X = X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dividing the data into training set and testing set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (400, 2)\n",
      "Shape of training result: (400, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[0:400]\n",
    "\n",
    "# create a temp array with all zeros of shape (400,2) for adding one extra column of ones\n",
    "shape_tuple = (X_train.shape[0],2);\n",
    "X_temp = np.zeros(shape_tuple)\n",
    "\n",
    "# create a column vector of shape (400,1) containing all the ones for X0\n",
    "column1 = np.ones(X_train.shape[0])\n",
    "\n",
    "# add this column as the first column of X_temp\n",
    "X_temp[:,0] = column1;\n",
    "\n",
    "# add the rest of the training data to it and finally assign it back to X_train\n",
    "X_temp[:,1:] = X_train.reshape(X_train.shape[0],1);\n",
    "X_train = X_temp;\n",
    "print(\"Shape of training data: {}\".format(X_train.shape))\n",
    "\n",
    "\n",
    "# getting our y_train vector\n",
    "y_train = y[0:400]\n",
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "print(\"Shape of training result: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106,)\n",
      "Shape of testing data: (106, 2)\n",
      "Shape of testing result: (106, 1)\n"
     ]
    }
   ],
   "source": [
    "# remaining data will be our testing data\n",
    "\n",
    "X_test = X[400:]\n",
    "print(X_test.shape)\n",
    "\n",
    "# create a temp array with all zeros of shape (400,2) for adding one extra column of ones\n",
    "shape_tuple = (X_test.shape[0],2);\n",
    "X_temp = np.zeros(shape_tuple)\n",
    "\n",
    "# create a column vector of shape (400,1) containing all the ones for X0\n",
    "column1 = np.ones(X_test.shape[0])\n",
    "\n",
    "# add this column as the first column of X_temp\n",
    "X_temp[:,0] = column1;\n",
    "\n",
    "# add the rest of the training data to it and finally assign it back to X_train\n",
    "X_temp[:,1:] = X_test.reshape(X_test.shape[0],1)\n",
    "X_test = X_temp\n",
    "print(\"Shape of testing data: {}\".format(X_test.shape))\n",
    "\n",
    "# getting our y_test vector\n",
    "y_test = y[400:]\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "print(\"Shape of testing result: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing feature scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52043246]\n",
      " [0.21194029]]\n"
     ]
    }
   ],
   "source": [
    "# initializing the theta vector with random uniform values between 0 and 1\n",
    "# shape of theta is (2,1)\n",
    "theta = np.random.uniform(0,1,(X_train.shape[1],1))\n",
    "print(theta)\n",
    "\n",
    "# feature scaling the X_train data to bring the range of values of all columns in [0,1]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ftting the data (i.e. finding out the mean and standard dev for normalization)\n",
    "scaler.fit(X_train[:,1:])\n",
    "\n",
    "# scaling the data and assigning it back to X_train and X_test\n",
    "X_train[:,1:] = scaler.transform(X_train[:,1:])\n",
    "X_test[:,1:] = scaler.transform(X_test[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying Normal Equation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.3345    ],\n",
       "       [-2.43098446]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.linalg.pinv(np.dot(X_train.T,X_train))\n",
    "B = np.dot(X_train.T,y_train)\n",
    "\n",
    "theta = np.dot(A,B)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 6.254842053073544\n",
      "MSE 53.50437706042421\n"
     ]
    }
   ],
   "source": [
    "prediction = np.dot(X_test,theta)\n",
    "\n",
    "print(\"MAE\", metrics.mean_absolute_error(y_true=y_test,y_pred = prediction))\n",
    "print(\"MSE\", metrics.mean_squared_error(y_true=y_test,y_pred = prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
