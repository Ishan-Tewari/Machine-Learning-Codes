{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdzwEhusnmkQ"
   },
   "source": [
    "# Implementing Naive Baye's with and without using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubKN-4O9JZJm"
   },
   "source": [
    "## Gaussian Naive Baye's with and without sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqLblPHKn7cu"
   },
   "source": [
    "**Impoting necessary libraries and datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3w8u018mroKm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import datasets,metrics\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "import math\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGXAPkE5ITi-"
   },
   "source": [
    "**Writing own class for Gaussian Naïve Baye's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C6JeDEwZr1bf"
   },
   "outputs": [],
   "source": [
    "class gaussClf:\n",
    "  # Separates the data by classes\n",
    "    def separate_by_classes(self, X, y):\n",
    "        \n",
    "        self.classes = np.unique(y)\n",
    "        classes_index = {}\n",
    "        subdatasets = {}\n",
    "        cls, counts = np.unique(y, return_counts=True)\n",
    "        self.class_freq = dict(zip(cls, counts))\n",
    "        print(\"Class frequency = {}\".format(self.class_freq))\n",
    "        for class_type in self.classes:\n",
    "            classes_index[class_type] = np.argwhere(y==class_type)\n",
    "            subdatasets[class_type] = X[classes_index[class_type], :]\n",
    "            self.class_freq[class_type] = self.class_freq[class_type]/sum(list(self.class_freq.values()))\n",
    "        return subdatasets\n",
    "\n",
    "  # Fitting the data\n",
    "    def fit(self, X, y):\n",
    "      separated_X = self.separate_by_classes(X, y)\n",
    "      # print(separated_X)\n",
    "      # print(self.classes)\n",
    "\n",
    "      self.means = {}\n",
    "      self.std = {}\n",
    "      for class_type in self.classes:\n",
    "          # Here we calculate the mean and the standart deviation from datasets\n",
    "          # print(np.mean(separated_X[class_type], axis=0))\n",
    "          self.means[class_type] = np.mean(separated_X[class_type], axis=0)[0]\n",
    "          self.std[class_type] = np.std(separated_X[class_type], axis=0)[0]\n",
    "\n",
    "  # Calculating the probability by Gaussian Formula\n",
    "    def calculate_probability(self, x, mean, stdev):\n",
    "      exponent = math.exp(-((x - mean) ** 2 / (2 * stdev ** 2)))\n",
    "      return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "  # Calculating probrabilty for our each datapoint to belong to a class\n",
    "    def predict_proba(self, X):\n",
    "      self.class_prob = {}\n",
    "      for cls in self.classes:\n",
    "          prob = self.class_freq[cls]/len(y)\n",
    "          self.class_prob[cls] = prob\n",
    "          for i in range(len(self.means)):\n",
    "              self.class_prob[cls] *= self.calculate_probability(X[i], self.means[cls][i], self.std[cls][i])\n",
    "          \n",
    "      return self.class_prob\n",
    "    \n",
    "  # Predicting the result\n",
    "    def predict(self, X):\n",
    "      ''' This funtion predicts the class of a sample '''\n",
    "      pred = []\n",
    "      for x in X:\n",
    "          pred_class = None\n",
    "          max_prob = 0\n",
    "          for cls, prob in self.predict_proba(x).items():\n",
    "              if prob>max_prob:\n",
    "                  max_prob = prob\n",
    "                  pred_class = cls\n",
    "          pred.append(pred_class)\n",
    "      return pred\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KwxgpOOIbtO"
   },
   "source": [
    "**Splitting the data into training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_fG26lHDsbey"
   },
   "outputs": [],
   "source": [
    "X,y = datasets.load_iris(return_X_y=True)\n",
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YpAOwBrIhqu"
   },
   "source": [
    "**Predicting using own classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciR9V4Qov16Y",
    "outputId": "73a70e73-7ef9-4b78-9ac4-e260686ca143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequency = {0: 37, 1: 34, 2: 41}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_scratch = gaussClf()\n",
    "clf_scratch.fit(X_train,y_train)\n",
    "prediction = clf_scratch.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_true=y_test,y_pred=prediction,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eetfO0EdIl7D"
   },
   "source": [
    "**Predicting using library function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-fi-IhEwJh3",
    "outputId": "a8c7c40a-5bef-48ea-fa83-e12e4abbccc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_true=y_test,y_pred=prediction,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmJ3hW--J_xf"
   },
   "source": [
    "## Multinomial and Bernoulli Naive Baye's using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEE_M9yTPr0X"
   },
   "source": [
    "**Importing Libraries and Reading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "q71PIvhvH2gN",
    "outputId": "46615c9c-ac0b-40af-ad11-11ac60bbc24c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  ... label_num\n",
       "0            605  ...         0\n",
       "1           2349  ...         0\n",
       "2           3624  ...         0\n",
       "3           4685  ...         1\n",
       "4           2030  ...         0\n",
       "...          ...  ...       ...\n",
       "5166        1518  ...         0\n",
       "5167         404  ...         0\n",
       "5168        2933  ...         0\n",
       "5169        1409  ...         0\n",
       "5170        4807  ...         1\n",
       "\n",
       "[5171 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "df = pd.read_csv('/content/drive/My Drive/spam_ham_dataset.csv',delimiter=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7n4qzCUpP5o3"
   },
   "source": [
    "**Tokenizing the text data and vectorizing it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSQ7SCnyNRYV",
    "outputId": "3a4a24c4-0f42-4520-dbcd-c807933e270f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3672\n",
       "1    1499\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english',ngram_range=(1,1))\n",
    "X = cv.fit_transform(df['text'])\n",
    "y = df['label_num']\n",
    "\n",
    "df.label_num.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tmnqzDmQMDP"
   },
   "source": [
    "**Dividing the data into training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "5AJvyuX4OC8D"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1L6JPr31QQzc"
   },
   "source": [
    "**Classification using Multinomial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0vloyjjPBlJ",
    "outputId": "b369bf2f-c60c-442c-d097-65cc01148eb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822119102861562"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfMNB = MultinomialNB()\n",
    "clfMNB.fit(X_train,y_train)\n",
    "prediction = clfMNB.predict(X_test)\n",
    "metrics.accuracy_score(y_true=y_test,y_pred = prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOaGIyvKQVH6"
   },
   "source": [
    "**Classification using Bernoulli**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrsFOYcmPZ2q",
    "outputId": "e379d01c-77bf-43f0-8950-b0c97d478ca6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8499613302397525"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfMNB = BernoulliNB()\n",
    "clfMNB.fit(X_train,y_train)\n",
    "prediction = clfMNB.predict(X_test)\n",
    "metrics.accuracy_score(y_true=y_test,y_pred = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7pkIiXJPhwZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "18BCE080_ML_Prac6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
